---
:description: A little bit about me...
---


I am a postdoctoral fellow at Harvard University currently working on reinforcement learning (RL) and deep learning methods motivated by real-world applications, particularly to mitigate the health impacts of climate change. I'm also interested in robotics ü§ñ and food üç£.

# Research

My research pursues generalizable methodology in reinforcement learning (RL) and deep learning motivated by real-world applications. Thus far, my approach has revolved around combining AI tools with principled statistical methods, particularly from Bayesian inference and causality. Owing to my interdisciplinary background in AI and statistics, I am well-positioned to contribute with innovative research aligned with Microsoft Research's goals (MSR) to build "intelligent decision-making agents that learn to understand their environment to make reliable routine decisions on behalf of people and organizations."

My current work as a postdoctoral fellow at Harvard University focuses on RL applications and spatial and higher-order {deep learning} architectures motivated by problems in climate and health. The integration of RL, representation learning, and statistical modeling holds an enormous potential for long-term impact on public health by allowing the development of intervention strategies to mitigate the health impacts of climate change. However, several methodological developments are needed for this to be possible, which I aim to solve. To illustrate an example, in \citet{rlheat}, we show that out-of-the-box RL methods cannot learn effective heat warning issuance policies during heatwaves in the United States. Explanations for these results include difficulties managing a budget over long-term horizons, reward sparsity, small sample sizes, low signal-to-noise ratio, and confounding and determinism in observable data. Our work offers solutions allowing RL algorithms to perform favorably against the National Weather Service policy. Nonetheless, much remains to be done methodologically to achieve impactful deployable solutions. 

Complementary to RL, my current research seeks to advance deep-learning methods for graph and geospatial data. This step is crucial to enable representations of heterogeneous multi-modal data characterizing optimal policies and their effectiveness across space and time, including climate, demographics, economic activity, and longitudinal health records. In \citet{weather2vec}, I introduced supervised and self-supervised methods for estimating causal effects under spatial lagged dependencies. Through this work, I discovered that a lack of benchmark tools hinders the development of new deep-learning methods for spatial causal inference. As a solution, I proposed SpaCE, the first benchmark toolkit with realistic semi-synthetic datasets affected by spatial confounding \citep{tec2023space}. SpaCE fills a gap in a much needed and growing ecosystem of machine-learning tools for causal inference, to which significant works within MSR have also contributed. In more recent work, I am investigating novel equivariant topological deep-learning architectures for learning expressive features with higher-order spatial data, which I intend to use for learning representations to improve RL and other AI applications in climate and health.


### Education

* Ph.D. in Statistics, The University of Texas at Austin, USA, 2022
* M.S. in Mathematics, University of Cambridge, UK, 2015
* B.S. in Applied Mathematics, ITAM, MX, 2013

### Experience
* Harvard University, Postdoctoral Fellow, 2022 - present
* Facebook AI Research, Research Intern, 2020
* Intel AI, Research Intern, 2019
* Graduate Research Assistant, The University of Texas at Austin, 2018 - 2021

## Full CV

[Download here](_static/cv.pdf). *Last updated:* 2023-12-15.

![family](_static/family.jpeg)
